{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (25, 3)\n",
      "t_data.ndim =  2 , t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('./data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "# 데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.36703553]\n",
      " [0.9889973 ]\n",
      " [0.50872623]] , W.shape =  (3, 1) , b =  [0.6347301] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3,1)  # 3X1 행렬\n",
    "b = np.random.rand(1)  \n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x,W) + b\n",
    "    \n",
    "    return ( np.sum( (t - y)**2 ) ) / ( len(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 손실함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    y = np.dot(x,W) + b\n",
    "    \n",
    "    return ( np.sum( (t - y)**2 ) ) / ( len(x) )\n",
    "\n",
    "# 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 x : numpy type\n",
    "def predict(x):\n",
    "    y = np.dot(x,W) + b\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  6.213283736351922 Initial W =  [[0.35884569]\n",
      " [0.53347527]\n",
      " [1.11378224]] , b =  [0.61968349]\n",
      "step =  0 error value =  6.213281746261937 W =  [[0.3588449 ]\n",
      " [0.53347286]\n",
      " [1.11378538]] , b =  [0.6196816]\n",
      "step =  400 error value =  6.212587507290592 W =  [[0.35854827]\n",
      " [0.53259329]\n",
      " [1.11494229]] , b =  [0.61892544]\n",
      "step =  800 error value =  6.212054933083214 W =  [[0.35828396]\n",
      " [0.53186587]\n",
      " [1.11591912]] , b =  [0.61816814]\n",
      "step =  1200 error value =  6.2116360925922836 W =  [[0.35804822]\n",
      " [0.531265  ]\n",
      " [1.11674454]] , b =  [0.61740991]\n",
      "step =  1600 error value =  6.211297320746041 W =  [[0.35783778]\n",
      " [0.53076932]\n",
      " [1.11744257]] , b =  [0.61665091]\n",
      "step =  2000 error value =  6.211014963021269 W =  [[0.35764976]\n",
      " [0.53036105]\n",
      " [1.11803342]] , b =  [0.61589127]\n",
      "step =  2400 error value =  6.210772391082429 W =  [[0.35748164]\n",
      " [0.53002533]\n",
      " [1.11853403]] , b =  [0.61513111]\n",
      "step =  2800 error value =  6.210557909519192 W =  [[0.35733119]\n",
      " [0.52974981]\n",
      " [1.11895864]] , b =  [0.61437053]\n",
      "step =  3200 error value =  6.210363287355377 W =  [[0.35719646]\n",
      " [0.52952419]\n",
      " [1.11931922]] , b =  [0.61360962]\n",
      "step =  3600 error value =  6.210182727647707 W =  [[0.35707573]\n",
      " [0.52933989]\n",
      " [1.11962581]] , b =  [0.61284843]\n",
      "step =  4000 error value =  6.210012144310849 W =  [[0.35696747]\n",
      " [0.52918979]\n",
      " [1.11988688]] , b =  [0.61208704]\n",
      "step =  4400 error value =  6.209848654426519 W =  [[0.35687034]\n",
      " [0.52906794]\n",
      " [1.12010952]] , b =  [0.61132548]\n",
      "step =  4800 error value =  6.209690221715717 W =  [[0.35678313]\n",
      " [0.52896942]\n",
      " [1.12029972]] , b =  [0.61056381]\n",
      "step =  5200 error value =  6.209535406073001 W =  [[0.3567048 ]\n",
      " [0.52889013]\n",
      " [1.1204625 ]] , b =  [0.60980205]\n",
      "step =  5600 error value =  6.209383187534728 W =  [[0.35663441]\n",
      " [0.52882666]\n",
      " [1.12060211]] , b =  [0.60904024]\n",
      "step =  6000 error value =  6.209232842499461 W =  [[0.35657111]\n",
      " [0.52877619]\n",
      " [1.12072211]] , b =  [0.60827839]\n",
      "step =  6400 error value =  6.2090838566392925 W =  [[0.35651418]\n",
      " [0.5287364 ]\n",
      " [1.12082551]] , b =  [0.60751655]\n",
      "step =  6800 error value =  6.2089358635852925 W =  [[0.35646294]\n",
      " [0.52870532]\n",
      " [1.12091484]] , b =  [0.60675471]\n",
      "step =  7200 error value =  6.208788601725103 W =  [[0.35641682]\n",
      " [0.52868138]\n",
      " [1.12099224]] , b =  [0.6059929]\n",
      "step =  7600 error value =  6.208641883735558 W =  [[0.35637528]\n",
      " [0.52866324]\n",
      " [1.12105951]] , b =  [0.60523113]\n",
      "step =  8000 error value =  6.2084955750736 W =  [[0.35633786]\n",
      " [0.5286498 ]\n",
      " [1.12111818]] , b =  [0.60446941]\n",
      "step =  8400 error value =  6.208349578773387 W =  [[0.35630414]\n",
      " [0.52864017]\n",
      " [1.12116953]] , b =  [0.60370775]\n",
      "step =  8800 error value =  6.208203824686404 W =  [[0.35627374]\n",
      " [0.52863361]\n",
      " [1.12121466]] , b =  [0.60294616]\n",
      "step =  9200 error value =  6.20805826185338 W =  [[0.35624633]\n",
      " [0.52862951]\n",
      " [1.12125448]] , b =  [0.60218465]\n",
      "step =  9600 error value =  6.207912853087429 W =  [[0.35622161]\n",
      " [0.52862736]\n",
      " [1.12128977]] , b =  [0.60142321]\n",
      "step =  10000 error value =  6.207767571119359 W =  [[0.35619931]\n",
      " [0.52862677]\n",
      " [1.12132119]] , b =  [0.60066186]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5  # 1e-2, 1e-3 은 손실함수 값 발산\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \", b = \", b )\n",
    "\n",
    "for step in  range(10001):  \n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \",b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.00059026])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "predict(test_data) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
