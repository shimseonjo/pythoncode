{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트환경\n",
    "####  운영체제 Windows 10  Pro\n",
    "#### 프로세서  intel(R) Core(TM) i7-8700 CPU @ 3.20GHz,  메모리(RAM) 16.0GB,  Anaconda 4.7.11,  jupyer notebook 6.00\n",
    "#### 테스트수행에는 강지현 학생이 도움을 주셨습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST_Test Class\n",
    "\n",
    "class MNIST_Test:\n",
    "    \n",
    "    # 생성자\n",
    "    # xdata, tdata => numpy.array(...)\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 은닉층 가중치  W2  Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # 출력층 가중치는 W3  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)      \n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        #self.W2 = np.random.rand(input_nodes, hidden_nodes)  \n",
    "        #self.b2 = np.random.rand(hidden_nodes)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 \n",
    "        #self.W3 = np.random.rand(hidden_nodes,output_nodes)\n",
    "        #self.b3 = np.random.rand(output_nodes)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        print(\"MNIST_Test object is created !!!\")\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # obtain W and b\n",
    "    def get_W_b(self):\n",
    "        \n",
    "        return self.W2,  self.b2, self.W3, self.b3\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):    \n",
    "        \n",
    "        z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "    \n",
    "        # MNIST 경우는 one-hot encoding 을 적용하기 때문에\n",
    "        # 0 또는 1 이 아닌 argmax() 를 통해 최대 인덱스를 넘겨주어야 함\n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        # list which contains (index, label, prediction) value\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        # temp list which contains label and prediction in sequence\n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "                        \n",
    "            label = int(target_data[index])\n",
    "                        \n",
    "            # normalize\n",
    "            data = (input_data[index, :] / 255.0 * 0.99) + 0.01\n",
    "      \n",
    "            predicted_num = self.predict(data)\n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                temp_list.append(index)\n",
    "                temp_list.append(label)\n",
    "                temp_list.append(predicted_num)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "                \n",
    "        print(\"Current Accuracy = \", len(matched_list)/(len(input_data)) )\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "        \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self, input_data, target_data):\n",
    "        \n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "    \n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        \n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "    \n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n"
     ]
    }
   ],
   "source": [
    "# training data \n",
    "training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_Test object is created !!!\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "epochs =  0 , index =  0 , loss value =  12.881948352151234\n",
      "epochs =  0 , index =  200 , loss value =  3.2624176452836373\n",
      "epochs =  0 , index =  400 , loss value =  2.742881750437296\n",
      "epochs =  0 , index =  600 , loss value =  2.9929679070910913\n",
      "epochs =  0 , index =  800 , loss value =  2.883778460432784\n",
      "epochs =  0 , index =  1000 , loss value =  2.5304509343096937\n",
      "epochs =  0 , index =  1200 , loss value =  1.9578392714612116\n",
      "epochs =  0 , index =  1400 , loss value =  1.8183808633861338\n",
      "epochs =  0 , index =  1600 , loss value =  3.161257155606402\n",
      "epochs =  0 , index =  1800 , loss value =  2.45740327709121\n",
      "epochs =  0 , index =  2000 , loss value =  3.101649014461739\n",
      "epochs =  0 , index =  2200 , loss value =  1.970792206051382\n",
      "epochs =  0 , index =  2400 , loss value =  1.7254714116831404\n",
      "epochs =  0 , index =  2600 , loss value =  2.551055112177881\n",
      "epochs =  0 , index =  2800 , loss value =  2.2482669567082554\n",
      "epochs =  0 , index =  3000 , loss value =  3.385585798042112\n",
      "epochs =  0 , index =  3200 , loss value =  2.1861497164708825\n",
      "epochs =  0 , index =  3400 , loss value =  1.317586415204215\n",
      "epochs =  0 , index =  3600 , loss value =  2.2873001508172104\n",
      "epochs =  0 , index =  3800 , loss value =  1.218128881694259\n",
      "epochs =  0 , index =  4000 , loss value =  1.1690722593611507\n",
      "epochs =  0 , index =  4200 , loss value =  1.502164330707141\n",
      "epochs =  0 , index =  4400 , loss value =  1.2020679415825888\n",
      "epochs =  0 , index =  4600 , loss value =  2.4683097102038967\n",
      "epochs =  0 , index =  4800 , loss value =  1.8861680115105737\n",
      "epochs =  0 , index =  5000 , loss value =  1.1919390277698119\n",
      "epochs =  0 , index =  5200 , loss value =  1.847774742528441\n",
      "epochs =  0 , index =  5400 , loss value =  1.9577999403557873\n",
      "epochs =  0 , index =  5600 , loss value =  1.6947736449086592\n",
      "epochs =  0 , index =  5800 , loss value =  2.4780549823559492\n",
      "epochs =  0 , index =  6000 , loss value =  0.7569268974843115\n",
      "epochs =  0 , index =  6200 , loss value =  1.9894318118535514\n",
      "epochs =  0 , index =  6400 , loss value =  0.9057605159168578\n",
      "epochs =  0 , index =  6600 , loss value =  2.012617636878228\n",
      "epochs =  0 , index =  6800 , loss value =  1.0056627355680219\n",
      "epochs =  0 , index =  7000 , loss value =  1.660864544335491\n",
      "epochs =  0 , index =  7200 , loss value =  1.8115331175968559\n",
      "epochs =  0 , index =  7400 , loss value =  1.540918593195829\n",
      "epochs =  0 , index =  7600 , loss value =  1.3733687565505377\n",
      "epochs =  0 , index =  7800 , loss value =  1.3466743716964276\n",
      "epochs =  0 , index =  8000 , loss value =  0.6316237490282133\n",
      "epochs =  0 , index =  8200 , loss value =  5.524174356137624\n",
      "epochs =  0 , index =  8400 , loss value =  1.3374053084710016\n",
      "epochs =  0 , index =  8600 , loss value =  2.53207781149564\n",
      "epochs =  0 , index =  8800 , loss value =  0.7847481633344227\n",
      "epochs =  0 , index =  9000 , loss value =  1.155883432776444\n",
      "epochs =  0 , index =  9200 , loss value =  0.7955971857480917\n",
      "epochs =  0 , index =  9400 , loss value =  0.8876355982593982\n",
      "epochs =  0 , index =  9600 , loss value =  0.6310886756788014\n",
      "epochs =  0 , index =  9800 , loss value =  1.8034784553206533\n",
      "epochs =  0 , index =  10000 , loss value =  0.6493220856851997\n",
      "epochs =  0 , index =  10200 , loss value =  1.0831613580118378\n",
      "epochs =  0 , index =  10400 , loss value =  1.541821231860299\n",
      "epochs =  0 , index =  10600 , loss value =  1.0192912777859124\n",
      "epochs =  0 , index =  10800 , loss value =  3.5949411037702306\n",
      "epochs =  0 , index =  11000 , loss value =  0.684875254212285\n",
      "epochs =  0 , index =  11200 , loss value =  0.6849001852926125\n",
      "epochs =  0 , index =  11400 , loss value =  0.7507653801468561\n",
      "epochs =  0 , index =  11600 , loss value =  5.836697520282227\n",
      "epochs =  0 , index =  11800 , loss value =  0.6776342140373731\n",
      "epochs =  0 , index =  12000 , loss value =  0.823707454970419\n",
      "epochs =  0 , index =  12200 , loss value =  1.0390922292516962\n",
      "epochs =  0 , index =  12400 , loss value =  0.6715571639764837\n",
      "epochs =  0 , index =  12600 , loss value =  2.0606601805261766\n",
      "epochs =  0 , index =  12800 , loss value =  1.4588228977683664\n",
      "epochs =  0 , index =  13000 , loss value =  0.9289048306394082\n",
      "epochs =  0 , index =  13200 , loss value =  1.7419141410411658\n",
      "epochs =  0 , index =  13400 , loss value =  1.157628623481256\n",
      "epochs =  0 , index =  13600 , loss value =  0.6759321653441084\n",
      "epochs =  0 , index =  13800 , loss value =  1.036246879894761\n",
      "epochs =  0 , index =  14000 , loss value =  0.646521738221405\n",
      "epochs =  0 , index =  14200 , loss value =  0.7833146796468966\n",
      "epochs =  0 , index =  14400 , loss value =  0.7305908213129094\n",
      "epochs =  0 , index =  14600 , loss value =  0.7250484791585464\n",
      "epochs =  0 , index =  14800 , loss value =  1.0799836779404026\n",
      "epochs =  0 , index =  15000 , loss value =  1.2523599004276618\n",
      "epochs =  0 , index =  15200 , loss value =  0.6178656057927524\n",
      "epochs =  0 , index =  15400 , loss value =  0.9312664598322405\n",
      "epochs =  0 , index =  15600 , loss value =  0.7560913668440543\n",
      "epochs =  0 , index =  15800 , loss value =  0.8720768191490287\n",
      "epochs =  0 , index =  16000 , loss value =  0.6326893427411598\n",
      "epochs =  0 , index =  16200 , loss value =  2.2000794566046564\n",
      "epochs =  0 , index =  16400 , loss value =  1.2980444994745939\n",
      "epochs =  0 , index =  16600 , loss value =  1.9120540993629742\n",
      "epochs =  0 , index =  16800 , loss value =  0.6047739073168029\n",
      "epochs =  0 , index =  17000 , loss value =  1.0028625972204024\n",
      "epochs =  0 , index =  17200 , loss value =  1.2336047645344688\n",
      "epochs =  0 , index =  17400 , loss value =  2.140849511195711\n",
      "epochs =  0 , index =  17600 , loss value =  0.8833369890917419\n",
      "epochs =  0 , index =  17800 , loss value =  0.869810126291595\n",
      "epochs =  0 , index =  18000 , loss value =  1.299196984280178\n",
      "epochs =  0 , index =  18200 , loss value =  1.0398887729029955\n",
      "epochs =  0 , index =  18400 , loss value =  0.6864081054672452\n",
      "epochs =  0 , index =  18600 , loss value =  0.8403957808753704\n",
      "epochs =  0 , index =  18800 , loss value =  0.6052815007879956\n",
      "epochs =  0 , index =  19000 , loss value =  0.8402815146791435\n",
      "epochs =  0 , index =  19200 , loss value =  0.7470803403714258\n",
      "epochs =  0 , index =  19400 , loss value =  0.7112216228508218\n",
      "epochs =  0 , index =  19600 , loss value =  1.1020486643239134\n",
      "epochs =  0 , index =  19800 , loss value =  0.654098082692828\n",
      "epochs =  0 , index =  20000 , loss value =  0.6554044354596805\n",
      "epochs =  0 , index =  20200 , loss value =  0.7107181481554476\n",
      "epochs =  0 , index =  20400 , loss value =  0.605533424120403\n",
      "epochs =  0 , index =  20600 , loss value =  2.0528818862558604\n",
      "epochs =  0 , index =  20800 , loss value =  0.7002064167917117\n",
      "epochs =  0 , index =  21000 , loss value =  1.5604209680117425\n",
      "epochs =  0 , index =  21200 , loss value =  0.6035334881935998\n",
      "epochs =  0 , index =  21400 , loss value =  0.6731017571310381\n",
      "epochs =  0 , index =  21600 , loss value =  0.6275918090870906\n",
      "epochs =  0 , index =  21800 , loss value =  0.7019985073708396\n",
      "epochs =  0 , index =  22000 , loss value =  1.140265567782202\n",
      "epochs =  0 , index =  22200 , loss value =  4.80009114947644\n",
      "epochs =  0 , index =  22400 , loss value =  1.653331719230969\n",
      "epochs =  0 , index =  22600 , loss value =  0.6228141222526455\n",
      "epochs =  0 , index =  22800 , loss value =  1.976931042335558\n",
      "epochs =  0 , index =  23000 , loss value =  0.6185429578833463\n",
      "epochs =  0 , index =  23200 , loss value =  1.3533662333286887\n",
      "epochs =  0 , index =  23400 , loss value =  2.1857309772278612\n",
      "epochs =  0 , index =  23600 , loss value =  0.741206194511574\n",
      "epochs =  0 , index =  23800 , loss value =  0.6172184871080303\n",
      "epochs =  0 , index =  24000 , loss value =  0.6714363758877887\n",
      "epochs =  0 , index =  24200 , loss value =  0.5957812330374723\n",
      "epochs =  0 , index =  24400 , loss value =  0.6766789595073057\n",
      "epochs =  0 , index =  24600 , loss value =  0.7905156155694619\n",
      "epochs =  0 , index =  24800 , loss value =  0.658784002288248\n",
      "epochs =  0 , index =  25000 , loss value =  2.0047917876486676\n",
      "epochs =  0 , index =  25200 , loss value =  1.4985966073687242\n",
      "epochs =  0 , index =  25400 , loss value =  1.021795744100727\n",
      "epochs =  0 , index =  25600 , loss value =  0.6267457756680151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , index =  25800 , loss value =  6.531137899910299\n",
      "epochs =  0 , index =  26000 , loss value =  0.694246857231124\n",
      "epochs =  0 , index =  26200 , loss value =  0.6448881284647963\n",
      "epochs =  0 , index =  26400 , loss value =  0.726126041838695\n",
      "epochs =  0 , index =  26600 , loss value =  3.326293294994974\n",
      "epochs =  0 , index =  26800 , loss value =  0.6265493206275325\n",
      "epochs =  0 , index =  27000 , loss value =  1.5240518359158453\n",
      "epochs =  0 , index =  27200 , loss value =  0.6408387831250868\n",
      "epochs =  0 , index =  27400 , loss value =  0.678904876861778\n",
      "epochs =  0 , index =  27600 , loss value =  0.5931656351408066\n",
      "epochs =  0 , index =  27800 , loss value =  0.6810557169488198\n",
      "epochs =  0 , index =  28000 , loss value =  0.6132191183422392\n",
      "epochs =  0 , index =  28200 , loss value =  1.5073185669686704\n",
      "epochs =  0 , index =  28400 , loss value =  0.6354520087657439\n",
      "epochs =  0 , index =  28600 , loss value =  1.043239388643466\n",
      "epochs =  0 , index =  28800 , loss value =  0.9286835859472982\n",
      "epochs =  0 , index =  29000 , loss value =  0.7610796406419904\n",
      "epochs =  0 , index =  29200 , loss value =  0.7085959811159239\n",
      "epochs =  0 , index =  29400 , loss value =  1.4465116951184487\n",
      "epochs =  0 , index =  29600 , loss value =  0.7731486660182036\n",
      "epochs =  0 , index =  29800 , loss value =  1.1934258559371973\n",
      "epochs =  0 , index =  30000 , loss value =  0.5982930175519582\n",
      "epochs =  0 , index =  30200 , loss value =  0.7632830709955363\n",
      "epochs =  0 , index =  30400 , loss value =  0.7689497487273423\n",
      "epochs =  0 , index =  30600 , loss value =  3.16764052927288\n",
      "epochs =  0 , index =  30800 , loss value =  1.2680112931499585\n",
      "epochs =  0 , index =  31000 , loss value =  2.8617467531635365\n",
      "epochs =  0 , index =  31200 , loss value =  4.436098988210796\n",
      "epochs =  0 , index =  31400 , loss value =  0.9119270945064692\n",
      "epochs =  0 , index =  31600 , loss value =  2.553863238583612\n",
      "epochs =  0 , index =  31800 , loss value =  0.949170206592914\n",
      "epochs =  0 , index =  32000 , loss value =  0.6287354093787165\n",
      "epochs =  0 , index =  32200 , loss value =  0.7200140151820932\n",
      "epochs =  0 , index =  32400 , loss value =  1.1538999044654294\n",
      "epochs =  0 , index =  32600 , loss value =  0.7199261268415337\n",
      "epochs =  0 , index =  32800 , loss value =  0.6017826447120644\n",
      "epochs =  0 , index =  33000 , loss value =  1.6020692234412106\n",
      "epochs =  0 , index =  33200 , loss value =  1.135222880842436\n",
      "epochs =  0 , index =  33400 , loss value =  0.688393450498751\n",
      "epochs =  0 , index =  33600 , loss value =  0.8132742649920344\n",
      "epochs =  0 , index =  33800 , loss value =  0.602211200463268\n",
      "epochs =  0 , index =  34000 , loss value =  1.1040597020576162\n",
      "epochs =  0 , index =  34200 , loss value =  0.8737929663919025\n",
      "epochs =  0 , index =  34400 , loss value =  0.6966203048581479\n",
      "epochs =  0 , index =  34600 , loss value =  1.0165046934551047\n",
      "epochs =  0 , index =  34800 , loss value =  4.150823288848209\n",
      "epochs =  0 , index =  35000 , loss value =  0.6051979683487553\n",
      "epochs =  0 , index =  35200 , loss value =  0.6456685898831779\n",
      "epochs =  0 , index =  35400 , loss value =  0.5829901637326118\n",
      "epochs =  0 , index =  35600 , loss value =  0.6102745667188003\n",
      "epochs =  0 , index =  35800 , loss value =  0.5864063224541007\n",
      "epochs =  0 , index =  36000 , loss value =  1.140426096954425\n",
      "epochs =  0 , index =  36200 , loss value =  0.7696903401155953\n",
      "epochs =  0 , index =  36400 , loss value =  0.6426797554203918\n",
      "epochs =  0 , index =  36600 , loss value =  0.7988432914373425\n",
      "epochs =  0 , index =  36800 , loss value =  0.8843490195740747\n",
      "epochs =  0 , index =  37000 , loss value =  0.6672209370520841\n",
      "epochs =  0 , index =  37200 , loss value =  0.6182940743369847\n",
      "epochs =  0 , index =  37400 , loss value =  1.0575675324657423\n",
      "epochs =  0 , index =  37600 , loss value =  0.8235210471080647\n",
      "epochs =  0 , index =  37800 , loss value =  0.7688573765483493\n",
      "epochs =  0 , index =  38000 , loss value =  0.7508324151468205\n",
      "epochs =  0 , index =  38200 , loss value =  0.583398205896955\n",
      "epochs =  0 , index =  38400 , loss value =  0.6581644342037392\n",
      "epochs =  0 , index =  38600 , loss value =  0.8282052613066115\n",
      "epochs =  0 , index =  38800 , loss value =  1.6233030123752072\n",
      "epochs =  0 , index =  39000 , loss value =  1.5310166766170448\n",
      "epochs =  0 , index =  39200 , loss value =  0.6486089169864347\n",
      "epochs =  0 , index =  39400 , loss value =  0.8380036545637068\n",
      "epochs =  0 , index =  39600 , loss value =  2.2726193989843906\n",
      "epochs =  0 , index =  39800 , loss value =  0.5993732931631389\n",
      "epochs =  0 , index =  40000 , loss value =  0.6280740081216731\n",
      "epochs =  0 , index =  40200 , loss value =  0.6621057431866093\n",
      "epochs =  0 , index =  40400 , loss value =  0.5982509891009322\n",
      "epochs =  0 , index =  40600 , loss value =  0.6647010146006831\n",
      "epochs =  0 , index =  40800 , loss value =  0.8323958716738916\n",
      "epochs =  0 , index =  41000 , loss value =  0.6951813681071347\n",
      "epochs =  0 , index =  41200 , loss value =  1.3506806657710975\n",
      "epochs =  0 , index =  41400 , loss value =  1.9665585478234542\n",
      "epochs =  0 , index =  41600 , loss value =  0.6190583980233164\n",
      "epochs =  0 , index =  41800 , loss value =  0.5837358609015878\n",
      "epochs =  0 , index =  42000 , loss value =  0.5822812265497097\n",
      "epochs =  0 , index =  42200 , loss value =  0.6489712730828731\n",
      "epochs =  0 , index =  42400 , loss value =  1.033194009619792\n",
      "epochs =  0 , index =  42600 , loss value =  0.6963215878772419\n",
      "epochs =  0 , index =  42800 , loss value =  1.0670040889168724\n",
      "epochs =  0 , index =  43000 , loss value =  2.1285720889404653\n",
      "epochs =  0 , index =  43200 , loss value =  1.4364476290755057\n",
      "epochs =  0 , index =  43400 , loss value =  0.7734310992725177\n",
      "epochs =  0 , index =  43600 , loss value =  0.7668049014743403\n",
      "epochs =  0 , index =  43800 , loss value =  1.0181422110537408\n",
      "epochs =  0 , index =  44000 , loss value =  0.6060893211266932\n",
      "epochs =  0 , index =  44200 , loss value =  0.8538004514834349\n",
      "epochs =  0 , index =  44400 , loss value =  0.6412819368062345\n",
      "epochs =  0 , index =  44600 , loss value =  0.673411213487133\n",
      "epochs =  0 , index =  44800 , loss value =  1.1433070453982959\n",
      "epochs =  0 , index =  45000 , loss value =  0.6550905183213015\n",
      "epochs =  0 , index =  45200 , loss value =  0.6040176460427374\n",
      "epochs =  0 , index =  45400 , loss value =  0.602073892313633\n",
      "epochs =  0 , index =  45600 , loss value =  0.6569117019631545\n",
      "epochs =  0 , index =  45800 , loss value =  5.14126714100746\n",
      "epochs =  0 , index =  46000 , loss value =  0.7403213358174902\n",
      "epochs =  0 , index =  46200 , loss value =  0.9853468631677175\n",
      "epochs =  0 , index =  46400 , loss value =  1.0351603417491293\n",
      "epochs =  0 , index =  46600 , loss value =  0.9271103807953115\n",
      "epochs =  0 , index =  46800 , loss value =  0.8272206041192649\n",
      "epochs =  0 , index =  47000 , loss value =  0.5987740791498216\n",
      "epochs =  0 , index =  47200 , loss value =  0.7238024920375763\n",
      "epochs =  0 , index =  47400 , loss value =  0.6043672440763499\n",
      "epochs =  0 , index =  47600 , loss value =  4.370856570712062\n",
      "epochs =  0 , index =  47800 , loss value =  0.6193669025489728\n",
      "epochs =  0 , index =  48000 , loss value =  0.8284780793401031\n",
      "epochs =  0 , index =  48200 , loss value =  0.9864858747718924\n",
      "epochs =  0 , index =  48400 , loss value =  0.6297110607167307\n",
      "epochs =  0 , index =  48600 , loss value =  0.5964464641989202\n",
      "epochs =  0 , index =  48800 , loss value =  2.236742796407087\n",
      "epochs =  0 , index =  49000 , loss value =  0.6261135096483657\n",
      "epochs =  0 , index =  49200 , loss value =  1.206797519803248\n",
      "epochs =  0 , index =  49400 , loss value =  0.8649895035755492\n",
      "epochs =  0 , index =  49600 , loss value =  0.8274322821235836\n",
      "epochs =  0 , index =  49800 , loss value =  0.7860590273703275\n",
      "epochs =  0 , index =  50000 , loss value =  0.7277176914348753\n",
      "epochs =  0 , index =  50200 , loss value =  0.5957531563040329\n",
      "epochs =  0 , index =  50400 , loss value =  0.6882432552875609\n",
      "epochs =  0 , index =  50600 , loss value =  0.5947896977604384\n",
      "epochs =  0 , index =  50800 , loss value =  0.6090267873030072\n",
      "epochs =  0 , index =  51000 , loss value =  0.6538135056664253\n",
      "epochs =  0 , index =  51200 , loss value =  2.6284930411058536\n",
      "epochs =  0 , index =  51400 , loss value =  0.695510294910498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , index =  51600 , loss value =  3.298195103169491\n",
      "epochs =  0 , index =  51800 , loss value =  0.6155033485731567\n",
      "epochs =  0 , index =  52000 , loss value =  0.6585992189435999\n",
      "epochs =  0 , index =  52200 , loss value =  0.8911444344470995\n",
      "epochs =  0 , index =  52400 , loss value =  1.1525214365458571\n",
      "epochs =  0 , index =  52600 , loss value =  0.9452385195554827\n",
      "epochs =  0 , index =  52800 , loss value =  2.8946391094533883\n",
      "epochs =  0 , index =  53000 , loss value =  0.6538382318596733\n",
      "epochs =  0 , index =  53200 , loss value =  0.6287252837966107\n",
      "epochs =  0 , index =  53400 , loss value =  0.634773941396035\n",
      "epochs =  0 , index =  53600 , loss value =  1.1539829157077615\n",
      "epochs =  0 , index =  53800 , loss value =  0.6462886985792997\n",
      "epochs =  0 , index =  54000 , loss value =  1.0004939874681706\n",
      "epochs =  0 , index =  54200 , loss value =  0.7420786402483764\n",
      "epochs =  0 , index =  54400 , loss value =  0.7953586612044115\n",
      "epochs =  0 , index =  54600 , loss value =  1.2438597480760796\n",
      "epochs =  0 , index =  54800 , loss value =  0.5783296168070596\n",
      "epochs =  0 , index =  55000 , loss value =  0.6272912220503095\n",
      "epochs =  0 , index =  55200 , loss value =  0.6853331072981188\n",
      "epochs =  0 , index =  55400 , loss value =  1.2517921467399233\n",
      "epochs =  0 , index =  55600 , loss value =  0.6399327985319541\n",
      "epochs =  0 , index =  55800 , loss value =  0.723649828632719\n",
      "epochs =  0 , index =  56000 , loss value =  0.5961073590794798\n",
      "epochs =  0 , index =  56200 , loss value =  0.6421434524549265\n",
      "epochs =  0 , index =  56400 , loss value =  0.692329167262188\n",
      "epochs =  0 , index =  56600 , loss value =  2.5711492876674673\n",
      "epochs =  0 , index =  56800 , loss value =  5.675540513965081\n",
      "epochs =  0 , index =  57000 , loss value =  0.592182842740394\n",
      "epochs =  0 , index =  57200 , loss value =  0.6260439272356745\n",
      "epochs =  0 , index =  57400 , loss value =  0.7378789827696212\n",
      "epochs =  0 , index =  57600 , loss value =  0.6379459431079637\n",
      "epochs =  0 , index =  57800 , loss value =  0.6564179033993285\n",
      "epochs =  0 , index =  58000 , loss value =  1.1703597365107876\n",
      "epochs =  0 , index =  58200 , loss value =  0.6616010387818898\n",
      "epochs =  0 , index =  58400 , loss value =  0.6822418186741878\n",
      "epochs =  0 , index =  58600 , loss value =  0.5854917913852319\n",
      "epochs =  0 , index =  58800 , loss value =  0.6390793127870256\n",
      "epochs =  0 , index =  59000 , loss value =  0.751943450144135\n",
      "epochs =  0 , index =  59200 , loss value =  0.5880837563562258\n",
      "epochs =  0 , index =  59400 , loss value =  3.007410588066169\n",
      "epochs =  0 , index =  59600 , loss value =  0.6170549447664146\n",
      "epochs =  0 , index =  59800 , loss value =  0.6065179201274236\n",
      "\n",
      "Elapsed Time =>  20:22:40.298186\n"
     ]
    }
   ],
   "source": [
    "#hyper-parameter\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 30  # hidden nodes 개수. Test 8->30\n",
    "o_nodes = 10    # output nodes 개수\n",
    "lr = 1e-2      # learning rate\n",
    "epochs = 1   # 반복횟수\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "\n",
    "# MNIST_Test 객체 생성\n",
    "obj = MNIST_Test(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epochs):\n",
    "    \n",
    "    for index in range(len(training_data)):    \n",
    "                \n",
    "        # input_data, target_data normalize    \n",
    "        input_data = ((training_data[index, 1:] / 255.0) * 0.99) + 0.01\n",
    "        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[index, 0])] = 0.99\n",
    "        \n",
    "        obj.train(input_data, target_data)\n",
    "        \n",
    "        if (index % 200 == 0):\n",
    "            print(\"epochs = \", step, \", index = \", index, \", loss value = \", obj.loss_val())\n",
    "            \n",
    "        # 손실함수 값 저장\n",
    "        loss_val_list.append(obj.loss_val())        \n",
    "\n",
    "end_time = datetime.now()\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "Current Accuracy =  0.924\n"
     ]
    }
   ],
   "source": [
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "\n",
    "test_input_data = test_data[ :, 1: ]\n",
    "test_target_data = test_data[ :, 0 ]\n",
    "\n",
    "(true_list_1, false_list_1, index_label_prediction_list) = obj.accuracy(test_input_data, test_target_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실함수 추세 확인\n",
    "x_data_list = [ index for index in range(len(training_data)) ]\n",
    "Y_DATA_LIST = []\n",
    "\n",
    "for index in range(0, len(loss_val_list), 500):\n",
    "    Y_DATA_LIST.append(loss_val_list[index])\n",
    "    \n",
    "plt.title('MNIST Loss Value Trend')\n",
    "plt.xlabel('data index ( X 500)')\n",
    "plt.ylabel('loss value')\n",
    "plt.grid()\n",
    "#plt.ylim(2.1, 7.1)\n",
    "#plt.plot(x_data_list, loss_val_list, color='b')\n",
    "plt.plot(Y_DATA_LIST, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
